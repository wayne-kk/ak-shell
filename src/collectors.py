#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é‡‡é›†å™¨æ¨¡å—
"""

import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict
from loguru import logger
import time
from retry import retry
from database import db
import random


class BaseCollector:
    """åŸºç¡€é‡‡é›†å™¨"""
    
    def __init__(self):
        self.retry_count = 3
        self.retry_delay = 5
        # å»¶æ—¶æ§åˆ¶é…ç½® - æ›´ä¿å®ˆçš„è®¾ç½®
        self.base_delay = 0.5   # åŸºç¡€å»¶æ—¶å¢åŠ åˆ°0.5ç§’
        self.random_delay = 0.8  # éšæœºå»¶æ—¶å¢åŠ åˆ°0.8ç§’
        self.batch_delay = 10.0   # æ‰¹æ¬¡é—´å»¶æ—¶å¢åŠ åˆ°10ç§’
        self.batch_size = 50     # æ‰¹æ¬¡å¤§å°å‡å°‘åˆ°50
    
    def set_delay_config(self, base_delay: float = 0.2, random_delay: float = 0.3, 
                        batch_delay: float = 2.0, batch_size: int = 100):
        """è®¾ç½®å»¶æ—¶é…ç½®"""
        self.base_delay = base_delay
        self.random_delay = random_delay
        self.batch_delay = batch_delay
        self.batch_size = batch_size
        logger.info(f"å»¶æ—¶é…ç½®å·²æ›´æ–°: åŸºç¡€å»¶æ—¶={base_delay}s, éšæœºå»¶æ—¶={random_delay}s, æ‰¹æ¬¡å»¶æ—¶={batch_delay}s, æ‰¹æ¬¡å¤§å°={batch_size}")
    
    def smart_delay(self, index: int = 0):
        """æ™ºèƒ½å»¶æ—¶æ§åˆ¶"""
        # åŸºç¡€å»¶æ—¶ + éšæœºå»¶æ—¶
        delay = self.base_delay + random.uniform(0, self.random_delay)
        time.sleep(delay)
        
        # æ¯æ‰¹æ¬¡åå¢åŠ é¢å¤–å»¶æ—¶
        if index > 0 and index % self.batch_size == 0:
            logger.info(f"æ‰¹æ¬¡å»¶æ—¶: {self.batch_delay}s")
            time.sleep(self.batch_delay)
    
    @retry(tries=3, delay=5)
    def safe_request(self, func, *args, **kwargs):
        """å®‰å…¨çš„APIè¯·æ±‚ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
            raise
    
    def clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†DataFrameæ•°æ®"""
        if df.empty:
            return df
        
        # æ›¿æ¢æ— ç©·å¤§å€¼
        df = df.replace([float('inf'), float('-inf')], None)
        
        # æ¸…ç†å­—ç¬¦ä¸²åˆ—çš„ç©ºæ ¼
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].astype(str).str.strip()
            df[col] = df[col].replace(['nan', 'None', ''], None)
        
        return df


class StockBasicCollector(BaseCollector):
    """è‚¡ç¥¨åŸºç¡€ä¿¡æ¯é‡‡é›†å™¨"""
    
    def collect(self) -> bool:
        """é‡‡é›†è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        logger.info("å¼€å§‹é‡‡é›†è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        
        try:
            # è·å–æ›´å…¨é¢çš„Aè‚¡è‚¡ç¥¨ä¿¡æ¯ï¼ˆä¸œè´¢æ•°æ®æºï¼‰
            logger.info("æ­£åœ¨ä»ä¸œè´¢è·å–è‚¡ç¥¨åˆ—è¡¨...")
            stock_em = self.safe_request(ak.stock_zh_a_spot_em)
            
            if stock_em.empty:
                logger.warning("ä¸œè´¢è‚¡ç¥¨ä¿¡æ¯ä¸ºç©ºï¼Œå°è¯•å¤‡ç”¨æ•°æ®æº...")
                # å¤‡ç”¨æ•°æ®æº
                stock_basic = self.safe_request(ak.stock_info_a_code_name)
                if stock_basic.empty:
                    logger.error("æ‰€æœ‰è‚¡ç¥¨æ•°æ®æºéƒ½ä¸ºç©º")
                    return False
                
                # é‡å‘½ååˆ—
                stock_basic = stock_basic.rename(columns={
                    'code': 'stock_code',
                    'name': 'stock_name'
                })
                # æ·»åŠ ç¼ºå¤±å­—æ®µ
                stock_basic['exchange'] = stock_basic['stock_code'].apply(self._get_market_by_code)
                stock_basic['update_time'] = datetime.now()
                
            else:
                # ä½¿ç”¨ä¸œè´¢æ•°æ®ï¼Œæ˜ å°„åˆ°æ¨¡å‹å­—æ®µ
                logger.info(f"è·å–åˆ° {len(stock_em)} åªè‚¡ç¥¨çš„ä¿¡æ¯")
                
                # å­—æ®µæ˜ å°„
                column_mapping = {
                    'ä»£ç ': 'stock_code',
                    'åç§°': 'stock_name',
                    'æ€»å¸‚å€¼': 'total_share',  # ç”¨æ€»å¸‚å€¼è¿‘ä¼¼ä»£æ›¿æ€»è‚¡æœ¬
                    'æµé€šå¸‚å€¼': 'float_share',  # ç”¨æµé€šå¸‚å€¼è¿‘ä¼¼ä»£æ›¿æµé€šè‚¡æœ¬
                    'å¸‚ç›ˆç‡-åŠ¨æ€': 'pe_ratio',  # ä¸´æ—¶å­—æ®µï¼Œç”¨äºåˆ¤æ–­STç­‰
                    'å¸‚å‡€ç‡': 'pb_ratio'  # ä¸´æ—¶å­—æ®µ
                }
                
                # åˆ›å»ºåŸºç¡€ä¿¡æ¯DataFrame
                stock_basic = pd.DataFrame()
                for old_col, new_col in column_mapping.items():
                    if old_col in stock_em.columns:
                        stock_basic[new_col] = stock_em[old_col]
                
                # æ·»åŠ æ´¾ç”Ÿå­—æ®µ
                if 'stock_code' in stock_basic.columns:
                    # äº¤æ˜“æ‰€åˆ¤æ–­
                    stock_basic['exchange'] = stock_basic['stock_code'].apply(self._get_market_by_code)
                    
                    # STåˆ¤æ–­ï¼ˆé€šè¿‡è‚¡ç¥¨åç§°åˆ¤æ–­ï¼‰
                    if 'stock_name' in stock_basic.columns:
                        stock_basic['is_st'] = stock_basic['stock_name'].str.contains('ST|st', regex=True, na=False)
                    
                    # çŠ¶æ€å­—æ®µï¼ˆç®€å•è®¾ä¸ºæ­£å¸¸ï¼‰
                    stock_basic['status'] = 'æ­£å¸¸'
                
                # ç§»é™¤ä¸´æ—¶å­—æ®µ
                temp_fields = ['pe_ratio', 'pb_ratio']
                for field in temp_fields:
                    if field in stock_basic.columns:
                        stock_basic = stock_basic.drop(columns=[field])
                
                # æ·»åŠ æ›´æ–°æ—¶é—´
                stock_basic['update_time'] = datetime.now()
            
            # æ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
            if 'total_share' in stock_basic.columns:
                stock_basic['total_share'] = pd.to_numeric(stock_basic['total_share'], errors='coerce')
            if 'float_share' in stock_basic.columns:
                stock_basic['float_share'] = pd.to_numeric(stock_basic['float_share'], errors='coerce')
            
            # æ¸…ç†æ•°æ®
            stock_basic = self.clean_dataframe(stock_basic)
            
            # ç§»é™¤ç©ºå€¼è¡Œ
            stock_basic = stock_basic.dropna(subset=['stock_code'])
            
            logger.info(f"å‡†å¤‡æ’å…¥ {len(stock_basic)} æ¡è‚¡ç¥¨åŸºç¡€ä¿¡æ¯")
            logger.info(f"æ•°æ®åˆ—: {stock_basic.columns.tolist()}")
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                stock_basic, 
                'stock_basic', 
                ['stock_code']
            )
            
            if success:
                logger.info(f"æˆåŠŸé‡‡é›†è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ {len(stock_basic)} æ¡")
            
            return success
            
        except Exception as e:
            logger.error(f"é‡‡é›†è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {e}")
            return False
    
    def _get_market_by_code(self, stock_code: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­æ‰€å±å¸‚åœº"""
        if not stock_code:
            return 'æœªçŸ¥'
        
        code = str(stock_code)
        if code.startswith('0') or code.startswith('2') or code.startswith('3'):
            return 'æ·±äº¤æ‰€'
        elif code.startswith('6') or code.startswith('9'):
            return 'ä¸Šäº¤æ‰€'
        elif code.startswith('8'):
            return 'åŒ—äº¤æ‰€'
        else:
            return 'å…¶ä»–'


class DailyQuoteCollector(BaseCollector):
    """æ—¥çº¿è¡Œæƒ…é‡‡é›†å™¨"""
    
    def collect_stock_history(self, stock_code: str, start_date: str, 
                            end_date: Optional[str] = None) -> bool:
        """é‡‡é›†å•ä¸ªè‚¡ç¥¨çš„å†å²æ•°æ®"""
        try:
            if end_date is None:
                end_date = datetime.now().strftime('%Y%m%d')
            
            logger.info(f"é‡‡é›†è‚¡ç¥¨ {stock_code} ä» {start_date} åˆ° {end_date} çš„è¡Œæƒ…æ•°æ®")
            
            # è·å–è‚¡ç¥¨å†å²æ•°æ®
            df = self.safe_request(
                ak.stock_zh_a_hist,
                symbol=stock_code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust=""
            )
            
            if df.empty:
                logger.warning(f"è‚¡ç¥¨ {stock_code} æ— å†å²æ•°æ®")
                return True
            
            # é‡å‘½ååˆ—
            column_mapping = {
                'æ—¥æœŸ': 'trade_date',
                'è‚¡ç¥¨ä»£ç ': 'stock_code',
                'å¼€ç›˜': 'open',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æ”¶ç›˜': 'close',
                'æ¶¨è·Œé¢': 'change',
                'æ¶¨è·Œå¹…': 'pct_chg',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount',
                'æŒ¯å¹…': 'amplitude',
                'æ¢æ‰‹ç‡': 'turnover_rate'
            }
            
            df = df.rename(columns=column_mapping)
            df['stock_code'] = stock_code
            df['update_time'] = datetime.now()
            
            # æ•°æ®ç±»å‹è½¬æ¢
            if 'trade_date' in df.columns:
                df['trade_date'] = pd.to_datetime(df['trade_date']).dt.date
            
            # æ¸…ç†æ•°æ®
            df = self.clean_dataframe(df)
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                df, 
                'daily_quote', 
                ['stock_code', 'trade_date']
            )
            
            if success:
                logger.info(f"æˆåŠŸé‡‡é›†è‚¡ç¥¨ {stock_code} è¡Œæƒ…æ•°æ® {len(df)} æ¡")
            
            # å»¶æ—¶æ§åˆ¶åœ¨è°ƒç”¨æ–¹å¤„ç†
            
            return success
            
        except Exception as e:
            logger.error(f"é‡‡é›†è‚¡ç¥¨ {stock_code} è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
            return False
    
    def collect_all_stocks_history(self, start_date: str, 
                                 end_date: Optional[str] = None, 
                                 enable_resume: bool = True) -> bool:
        """é‡‡é›†æ‰€æœ‰è‚¡ç¥¨çš„å†å²æ•°æ®ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
        logger.info("å¼€å§‹é‡‡é›†æ‰€æœ‰è‚¡ç¥¨å†å²è¡Œæƒ…æ•°æ®...")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = db.get_stock_list()
        if not stock_list:
            logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
        
        success_count = 0
        skip_count = 0
        total_count = len(stock_list)
        logger.info("è‚¡ç¥¨åˆ—è¡¨æ•°é‡:",total_count)
        for i, stock_code in enumerate(stock_list, 1):
            logger.info(f"å¤„ç†è¿›åº¦: {i}/{total_count} - {stock_code}")
            
            # æ–­ç‚¹ç»­ä¼ æ£€æŸ¥
            if enable_resume:
                latest_date = db.get_latest_date('daily_quote', 'trade_date', stock_code)
                if latest_date:
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å®Œæ•´çš„æ•°æ®
                    if end_date and latest_date >= end_date:
                        logger.info(f"è‚¡ç¥¨ {stock_code} æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡")
                        skip_count += 1
                        continue
                    # ä»æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹é‡‡é›†
                    resume_start_date = (datetime.strptime(latest_date, '%Y%m%d') + timedelta(days=1)).strftime('%Y%m%d')
                    if resume_start_date > start_date:
                        logger.info(f"è‚¡ç¥¨ {stock_code} ä» {resume_start_date} å¼€å§‹ç»­ä¼ ")
                        start_date_for_stock = resume_start_date
                    else:
                        start_date_for_stock = start_date
                else:
                    start_date_for_stock = start_date
            else:
                start_date_for_stock = start_date
            
            # é‡‡é›†æ•°æ®
            if self.collect_stock_history(stock_code, start_date_for_stock, end_date):
                success_count += 1
            
            # æ™ºèƒ½å»¶æ—¶æ§åˆ¶
            self.smart_delay(i)
            
            # æ¯100åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
            if i % 100 == 0:
                logger.info(f"å·²å¤„ç† {i}/{total_count} åªè‚¡ç¥¨ï¼ŒæˆåŠŸ {success_count} åªï¼Œè·³è¿‡ {skip_count} åª")
        
        logger.info(f"å†å²æ•°æ®é‡‡é›†å®Œæˆ: æ€»è®¡ {total_count} åªè‚¡ç¥¨ï¼ŒæˆåŠŸ {success_count} åªï¼Œè·³è¿‡ {skip_count} åª")
        return success_count > 0
    
    def collect_latest_quotes_batch(self) -> bool:
        """æ‰¹é‡é‡‡é›†æœ€æ–°è¡Œæƒ…æ•°æ®ï¼ˆé¿å…é¢‘ç¹APIè¯·æ±‚ï¼‰"""
        logger.info("å¼€å§‹æ‰¹é‡é‡‡é›†æœ€æ–°è¡Œæƒ…æ•°æ®...")
        
        try:
            # ä½¿ç”¨æ›´ç¨³å®šçš„æ‰¹é‡æ¥å£è·å–æ‰€æœ‰è‚¡ç¥¨æœ€æ–°æ•°æ®
            logger.info("æ­£åœ¨è·å–æ‰€æœ‰è‚¡ç¥¨æœ€æ–°è¡Œæƒ…...")
            df = self.safe_request(ak.stock_zh_a_spot_em)
            
            if df.empty:
                logger.warning("æ‰¹é‡è¡Œæƒ…æ•°æ®ä¸ºç©º")
                return False
            
            logger.info(f"è·å–åˆ° {len(df)} åªè‚¡ç¥¨çš„æœ€æ–°è¡Œæƒ…")
            
            # åªé€‰æ‹©æ•°æ®åº“ä¸­å­˜åœ¨çš„æ ¸å¿ƒè¡Œæƒ…å­—æ®µ
            basic_columns = {
                'ä»£ç ': 'stock_code',
                'æœ€æ–°ä»·': 'close',
                'æ¶¨è·Œé¢': 'change',
                'æ¶¨è·Œå¹…': 'pct_chg',
                'ä»Šå¼€': 'open',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume',
                'æˆäº¤é¢': 'amount'
            }
            
            # åˆ›å»ºæ–°çš„DataFrameï¼ŒåªåŒ…å«æ ¸å¿ƒè¡Œæƒ…å­—æ®µ
            processed_data = {}
            for old_col, new_col in basic_columns.items():
                if old_col in df.columns:
                    processed_data[new_col] = df[old_col]
                else:
                    processed_data[new_col] = None
            
            # åˆ›å»ºæ–°çš„DataFrame
            df_clean = pd.DataFrame(processed_data)
            
            # æ·»åŠ äº¤æ˜“æ—¥æœŸï¼ˆä½¿ç”¨å½“å‰æ—¥æœŸï¼‰
            today = datetime.now().date()
            df_clean['trade_date'] = today
            df_clean['update_time'] = datetime.now()
            
            # æ¸…ç†æ•°æ®
            df_clean = self.clean_dataframe(df_clean)
            
            # æ•°æ®ç±»å‹è½¬æ¢
            try:
                # è½¬æ¢æ•°å€¼ç±»å‹å­—æ®µ
                numeric_fields = ['close', 'change', 'pct_chg', 'open', 'high', 'low', 'amount']
                for field in numeric_fields:
                    if field in df_clean.columns:
                        df_clean[field] = pd.to_numeric(df_clean[field], errors='coerce')
                
                # æˆäº¤é‡è½¬æ¢ä¸ºæ•´æ•°
                if 'volume' in df_clean.columns:
                    df_clean['volume'] = pd.to_numeric(df_clean['volume'], errors='coerce')
                    df_clean['volume'] = df_clean['volume'].fillna(0).astype('int64')
                
            except Exception as e:
                logger.warning(f"æ•°æ®ç±»å‹è½¬æ¢æ—¶å‡ºç°è­¦å‘Š: {e}")
            
            # ç§»é™¤ç©ºå€¼è¡Œ
            df_clean = df_clean.dropna(subset=['stock_code'])
            
            logger.info(f"å‡†å¤‡æ’å…¥ {len(df_clean)} æ¡æœ€æ–°è¡Œæƒ…æ•°æ®")
            logger.info(f"æ•°æ®åˆ—: {df_clean.columns.tolist()}")
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                df_clean, 
                'daily_quote', 
                ['stock_code', 'trade_date']
            )
            
            if success:
                logger.info(f"æˆåŠŸæ‰¹é‡é‡‡é›†æœ€æ–°è¡Œæƒ…æ•°æ® {len(df_clean)} æ¡")
                logger.info("ğŸš€ æ‰¹é‡é‡‡é›†é¿å…äº†æ•°åƒæ¬¡å•ç‹¬APIè¯·æ±‚ï¼")
            
            return success
            
        except Exception as e:
            logger.error(f"æ‰¹é‡é‡‡é›†æœ€æ–°è¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
            return False

    def collect_latest_quotes(self) -> bool:
        """é‡‡é›†æœ€æ–°è¡Œæƒ…æ•°æ®"""
        logger.info("å¼€å§‹é‡‡é›†æœ€æ–°è¡Œæƒ…æ•°æ®...")
        
        # ä¼˜å…ˆå°è¯•æ‰¹é‡é‡‡é›†
        batch_success = self.collect_latest_quotes_batch()
        if batch_success:
            logger.info("æ‰¹é‡é‡‡é›†æˆåŠŸï¼Œæ— éœ€å•ç‹¬é‡‡é›†")
            return True
        
        logger.warning("æ‰¹é‡é‡‡é›†å¤±è´¥ï¼Œå›é€€åˆ°å•ç‹¬é‡‡é›†æ¨¡å¼...")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stock_list = db.get_stock_list()
        if not stock_list:
            logger.error("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
            return False
        
        today = datetime.now().strftime('%Y%m%d')
        success_count = 0
        
        for i, stock_code in enumerate(stock_list, 1):
            # è·å–è¯¥è‚¡ç¥¨æœ€æ–°æ—¥æœŸ
            latest_date = db.get_latest_date('daily_quote', 'trade_date', stock_code)
            
            # å¦‚æœæœ‰æœ€æ–°æ—¥æœŸï¼Œä»ä¸‹ä¸€å¤©å¼€å§‹é‡‡é›†
            if latest_date:
                start_date = (datetime.strptime(latest_date, '%Y%m%d') + timedelta(days=1)).strftime('%Y%m%d')
            else:
                # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œé‡‡é›†æœ€è¿‘30å¤©
                start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
            
            if start_date <= today:
                if self.collect_stock_history(stock_code, start_date, today):
                    success_count += 1
            
            # æ™ºèƒ½å»¶æ—¶æ§åˆ¶
            self.smart_delay(i)
        
        logger.info(f"å•ç‹¬é‡‡é›†æ¨¡å¼å®Œæˆ: æˆåŠŸæ›´æ–° {success_count} åªè‚¡ç¥¨")
        return success_count > 0


class IndexDataCollector(BaseCollector):
    """æŒ‡æ•°æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self):
        super().__init__()
        self.index_list = [
            ('sh000001', 'ä¸Šè¯æŒ‡æ•°'),
            ('sz399001', 'æ·±è¯æˆæŒ‡'),
            ('sz399006', 'åˆ›ä¸šæ¿æŒ‡'),
            ('sh000300', 'æ²ªæ·±300'),
            ('sh000905', 'ä¸­è¯500')
        ]
    

    
    def collect_all_indexes_history(self, start_date: str, 
                                  end_date: Optional[str] = None,
                                  retry_delay_hours: int = 1) -> bool:
        """é‡‡é›†æ‰€æœ‰æŒ‡æ•°å†å²æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            retry_delay_hours: å½“æ•°æ®æºæœªæ›´æ–°æ—¶çš„é‡è¯•å»¶è¿Ÿå°æ—¶æ•°
        """
        logger.info("å¼€å§‹é‡‡é›†æŒ‡æ•°å†å²æ•°æ®...")
        
        success_count = 0
        has_data_count = 0  # å®é™…æœ‰æ•°æ®çš„æŒ‡æ•°æ•°é‡
        
        for i, (index_code, index_name) in enumerate(self.index_list, 1):
            result = self.collect_index_history_with_data_check(index_code, index_name, start_date, end_date)
            if result['success']:
                success_count += 1
            if result['has_data']:
                has_data_count += 1
            # æŒ‡æ•°æ•°æ®é‡‡é›†é—´éš”å»¶æ—¶
            if i < len(self.index_list):  # æœ€åä¸€ä¸ªä¸éœ€è¦å»¶æ—¶
                time.sleep(1.0)
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æŒ‡æ•°éƒ½æ²¡æœ‰æ•°æ®ï¼ˆå¯èƒ½æ•°æ®æºæœªæ›´æ–°ï¼‰
        if has_data_count == 0 and success_count == len(self.index_list):
            logger.warning(f"æ‰€æœ‰æŒ‡æ•°åœ¨ {start_date} éƒ½æ²¡æœ‰æ•°æ®ï¼Œå¯èƒ½æ•°æ®æºæœªæ›´æ–°")
            
            # å¦‚æœæ˜¯å½“æ—¥æ•°æ®ä¸”æ—¶é—´è¿˜æ—©ï¼Œå»ºè®®å»¶è¿Ÿé‡è¯•
            current_hour = datetime.now().hour
            if start_date == datetime.now().strftime('%Y%m%d') and current_hour < 20:
                logger.info(f"å»ºè®® {retry_delay_hours} å°æ—¶åé‡è¯•ï¼Œå½“å‰æ—¶é—´: {datetime.now().strftime('%H:%M')}")
                logger.info(f"å¯åœ¨ {(datetime.now() + timedelta(hours=retry_delay_hours)).strftime('%H:%M')} åé‡æ–°æ‰§è¡Œ")
                
                # å¯ä»¥é€‰æ‹©ç«‹å³é‡è¯•ä¸€æ¬¡ï¼ˆç­‰å¾…1å°æ—¶ï¼‰
                if self._should_retry_index_collection():
                    logger.info("å¯åŠ¨è‡ªåŠ¨é‡è¯•æœºåˆ¶...")
                    return self._retry_index_collection_later(start_date, end_date, retry_delay_hours)
        
        logger.info(f"æŒ‡æ•°å†å²æ•°æ®é‡‡é›†å®Œæˆ: æˆåŠŸ {success_count}/{len(self.index_list)} ä¸ªæŒ‡æ•°ï¼Œæœ‰æ•°æ® {has_data_count} ä¸ª")
        return success_count > 0

    def collect_index_history_with_data_check(self, index_code: str, index_name: str,
                                            start_date: str, end_date: Optional[str] = None) -> dict:
        """é‡‡é›†æŒ‡æ•°å†å²æ•°æ®å¹¶æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®"""
        try:
            if end_date is None:
                end_date = datetime.now().strftime('%Y%m%d')
            
            logger.info(f"é‡‡é›†æŒ‡æ•° {index_code}({index_name}) ä» {start_date} åˆ° {end_date} çš„æ•°æ®")
            
            # è·å–æŒ‡æ•°æ•°æ®
            df = self.safe_request(
                ak.stock_zh_index_daily,
                symbol=index_code
            )
            
            if df.empty:
                logger.warning(f"æŒ‡æ•° {index_code} æ— å†å²æ•°æ®")
                return {'success': True, 'has_data': False}
            
            # è¿‡æ»¤æ—¥æœŸèŒƒå›´
            df['date'] = pd.to_datetime(df['date'])
            start_dt = datetime.strptime(start_date, '%Y%m%d')
            end_dt = datetime.strptime(end_date, '%Y%m%d')
            df = df[(df['date'] >= start_dt) & (df['date'] <= end_dt)]
            
            if df.empty:
                logger.info(f"æŒ‡æ•° {index_code} åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ— æ•°æ®")
                return {'success': True, 'has_data': False}
            
            # é‡å‘½åå’Œæ·»åŠ åˆ—
            df = df.rename(columns={'date': 'trade_date'})
            df['index_code'] = index_code
            df['index_name'] = index_name
            df['trade_date'] = df['trade_date'].dt.date
            df['update_time'] = datetime.now()
            
            # è®¡ç®—æ¶¨è·Œé¢å’Œæ¶¨è·Œå¹…
            df = df.sort_values('trade_date')
            df['change'] = df['close'].diff()
            df['pct_chg'] = df['close'].pct_change() * 100
            
            # æ¸…ç†æ•°æ®
            df = self.clean_dataframe(df)
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                df,
                'index_data',
                ['index_code', 'trade_date']
            )
            
            if success:
                logger.info(f"æˆåŠŸé‡‡é›†æŒ‡æ•° {index_code} æ•°æ® {len(df)} æ¡")
            
            return {'success': success, 'has_data': True}
            
        except Exception as e:
            logger.error(f"é‡‡é›†æŒ‡æ•° {index_code} æ•°æ®å¤±è´¥: {e}")
            return {'success': False, 'has_data': False}

    def _should_retry_index_collection(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•æŒ‡æ•°æ•°æ®é‡‡é›†"""
        current_time = datetime.now()
        current_hour = current_time.hour
        
        # åªåœ¨äº¤æ˜“æ—¥çš„ç‰¹å®šæ—¶é—´æ®µå†…é‡è¯•
        if current_time.weekday() >= 5:  # å‘¨æœ«ä¸é‡è¯•
            return False
        
        # åœ¨18:00-21:00ä¹‹é—´å¯ä»¥é‡è¯•
        if 18 <= current_hour <= 21:
            return True
        
        return False

    def _retry_index_collection_later(self, start_date: str, end_date: Optional[str], 
                                    delay_hours: int) -> bool:
        """å»¶è¿Ÿé‡è¯•æŒ‡æ•°æ•°æ®é‡‡é›†"""
        import threading
        import time as time_module
        
        def delayed_retry():
            logger.info(f"ç­‰å¾… {delay_hours} å°æ—¶åé‡è¯•æŒ‡æ•°æ•°æ®é‡‡é›†...")
            time_module.sleep(delay_hours * 3600)  # è½¬æ¢ä¸ºç§’
            
            logger.info("å¼€å§‹é‡è¯•æŒ‡æ•°æ•°æ®é‡‡é›†...")
            retry_result = self.collect_all_indexes_history(start_date, end_date, retry_delay_hours=0)
            
            if retry_result:
                logger.info("é‡è¯•æˆåŠŸï¼šæŒ‡æ•°æ•°æ®é‡‡é›†å®Œæˆ")
                # å‘é€æˆåŠŸé€šçŸ¥
                try:
                    from feishu_notify import send_completion_notice
                    send_completion_notice(
                        "æŒ‡æ•°æ•°æ®é‡è¯•é‡‡é›†",
                        True,
                        {
                            "é‡è¯•æ—¶é—´": datetime.now().strftime('%H:%M:%S'),
                            "é‡‡é›†æ—¥æœŸ": start_date,
                            "çŠ¶æ€": "âœ… é‡è¯•æˆåŠŸ"
                        }
                    )
                except:
                    pass
            else:
                logger.warning("é‡è¯•å¤±è´¥ï¼šæŒ‡æ•°æ•°æ®ä»ç„¶æ— æ³•è·å–")
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå»¶è¿Ÿé‡è¯•
        retry_thread = threading.Thread(target=delayed_retry, daemon=True)
        retry_thread.start()
        
        logger.info(f"å·²å¯åŠ¨åå°é‡è¯•ä»»åŠ¡ï¼Œå°†åœ¨ {delay_hours} å°æ—¶åè‡ªåŠ¨é‡è¯•")
        return True  # è¿”å›Trueè¡¨ç¤ºå·²å®‰æ’é‡è¯•


class TradeCalendarCollector(BaseCollector):
    """äº¤æ˜“æ—¥å†é‡‡é›†å™¨"""
    
    def collect(self, start_year: Optional[int] = None) -> bool:
        """é‡‡é›†äº¤æ˜“æ—¥å†"""
        logger.info("å¼€å§‹é‡‡é›†äº¤æ˜“æ—¥å†...")
        
        try:
            if start_year is None:
                start_year = datetime.now().year - 5
            
            # è·å–äº¤æ˜“æ—¥å†
            trade_dates = self.safe_request(ak.tool_trade_date_hist_sina)
            
            if trade_dates.empty:
                logger.warning("äº¤æ˜“æ—¥å†æ•°æ®ä¸ºç©º")
                return False
            
            # è¿‡æ»¤å¹´ä»½
            trade_dates['trade_date'] = pd.to_datetime(trade_dates['trade_date'])
            trade_dates = trade_dates[trade_dates['trade_date'].dt.year >= start_year]
            
            # é‡å‘½ååˆ—
            trade_dates = trade_dates.rename(columns={'trade_date': 'calendar_date'})
            trade_dates['calendar_date'] = trade_dates['calendar_date'].dt.date
            trade_dates['is_trade_day'] = True
            trade_dates['week_day'] = pd.to_datetime(trade_dates['calendar_date']).dt.dayofweek
            trade_dates['is_holiday'] = False
            trade_dates['update_time'] = datetime.now()
            
            # æ¸…ç†æ•°æ®
            trade_dates = self.clean_dataframe(trade_dates)
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                trade_dates,
                'trade_calendar',
                ['calendar_date']
            )
            
            if success:
                logger.info(f"æˆåŠŸé‡‡é›†äº¤æ˜“æ—¥å† {len(trade_dates)} æ¡")
            
            return success
            
        except Exception as e:
            logger.error(f"é‡‡é›†äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            return False


class StockHotRankCollector(BaseCollector):
    """è‚¡ç¥¨äººæ°”æ¦œé‡‡é›†å™¨"""
    
    def collect_hot_rank(self) -> bool:
        """é‡‡é›†è‚¡ç¥¨äººæ°”æ¦œæ•°æ®"""
        logger.info("å¼€å§‹é‡‡é›†è‚¡ç¥¨äººæ°”æ¦œæ•°æ®...")
        
        try:
            # è·å–äººæ°”æ¦œæ•°æ®
            df = self.safe_request(ak.stock_hot_rank_em)
            
            if df.empty:
                logger.warning("äººæ°”æ¦œæ•°æ®ä¸ºç©º")
                return False
            
            logger.info(f"è·å–åˆ° {len(df)} æ¡äººæ°”æ¦œæ•°æ®")
            
            # å­—æ®µæ˜ å°„
            column_mapping = {
                'å½“å‰æ’å': 'current_rank',
                'ä»£ç ': 'stock_code',
                'è‚¡ç¥¨åç§°': 'stock_name',
                'æœ€æ–°ä»·': 'latest_price',
                'æ¶¨è·Œé¢': 'change',
                'æ¶¨è·Œå¹…': 'pct_chg'
            }
            
            # é‡å‘½ååˆ—
            df = df.rename(columns=column_mapping)
            
            # æ·»åŠ äº¤æ˜“æ—¥æœŸå’Œæ›´æ–°æ—¶é—´
            today = datetime.now().date()
            df['trade_date'] = today
            df['update_time'] = datetime.now()
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_fields = ['current_rank', 'latest_price', 'change', 'pct_chg']
            for field in numeric_fields:
                if field in df.columns:
                    df[field] = pd.to_numeric(df[field], errors='coerce')
            
            # æ¸…ç†æ•°æ®
            df = self.clean_dataframe(df)
            
            # ç§»é™¤ç©ºå€¼è¡Œ
            df = df.dropna(subset=['stock_code', 'current_rank'])
            
            logger.info(f"å‡†å¤‡æ’å…¥ {len(df)} æ¡äººæ°”æ¦œæ•°æ®")
            logger.info(f"æ•°æ®åˆ—: {df.columns.tolist()}")
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                df,
                'stock_hot_rank',
                ['trade_date', 'current_rank']
            )
            
            if success:
                logger.info(f"âœ… æˆåŠŸé‡‡é›†è‚¡ç¥¨äººæ°”æ¦œæ•°æ® {len(df)} æ¡")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ é‡‡é›†è‚¡ç¥¨äººæ°”æ¦œæ•°æ®å¤±è´¥: {e}")
            return False


class StockHotUpCollector(BaseCollector):
    """è‚¡ç¥¨é£™å‡æ¦œé‡‡é›†å™¨"""
    
    def collect_hot_up(self) -> bool:
        """é‡‡é›†è‚¡ç¥¨é£™å‡æ¦œæ•°æ®"""
        logger.info("å¼€å§‹é‡‡é›†è‚¡ç¥¨é£™å‡æ¦œæ•°æ®...")
        
        try:
            # è·å–é£™å‡æ¦œæ•°æ®
            df = self.safe_request(ak.stock_hot_up_em)
            
            if df.empty:
                logger.warning("é£™å‡æ¦œæ•°æ®ä¸ºç©º")
                return False
            
            logger.info(f"è·å–åˆ° {len(df)} æ¡é£™å‡æ¦œæ•°æ®")
            
            # å­—æ®µæ˜ å°„
            column_mapping = {
                'æ’åè¾ƒæ˜¨æ—¥å˜åŠ¨': 'rank_change',
                'å½“å‰æ’å': 'current_rank',
                'ä»£ç ': 'stock_code',
                'è‚¡ç¥¨åç§°': 'stock_name',
                'æœ€æ–°ä»·': 'latest_price',
                'æ¶¨è·Œé¢': 'change',
                'æ¶¨è·Œå¹…': 'pct_chg'
            }
            
            # é‡å‘½ååˆ—
            df = df.rename(columns=column_mapping)
            
            # æ·»åŠ äº¤æ˜“æ—¥æœŸå’Œæ›´æ–°æ—¶é—´
            today = datetime.now().date()
            df['trade_date'] = today
            df['update_time'] = datetime.now()
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_fields = ['rank_change', 'current_rank', 'latest_price', 'change', 'pct_chg']
            for field in numeric_fields:
                if field in df.columns:
                    df[field] = pd.to_numeric(df[field], errors='coerce')
            
            # æ¸…ç†æ•°æ®
            df = self.clean_dataframe(df)
            
            # ç§»é™¤ç©ºå€¼è¡Œ
            df = df.dropna(subset=['stock_code', 'current_rank'])
            
            logger.info(f"å‡†å¤‡æ’å…¥ {len(df)} æ¡é£™å‡æ¦œæ•°æ®")
            logger.info(f"æ•°æ®åˆ—: {df.columns.tolist()}")
            
            # æ’å…¥æ•°æ®åº“
            success = db.upsert_dataframe(
                df,
                'stock_hot_up',
                ['trade_date', 'current_rank']
            )
            
            if success:
                logger.info(f"âœ… æˆåŠŸé‡‡é›†è‚¡ç¥¨é£™å‡æ¦œæ•°æ® {len(df)} æ¡")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ é‡‡é›†è‚¡ç¥¨é£™å‡æ¦œæ•°æ®å¤±è´¥: {e}")
            return False


# é‡‡é›†å™¨å®ä¾‹
stock_basic_collector = StockBasicCollector()
daily_quote_collector = DailyQuoteCollector()
index_data_collector = IndexDataCollector()
trade_calendar_collector = TradeCalendarCollector()
stock_hot_rank_collector = StockHotRankCollector()
stock_hot_up_collector = StockHotUpCollector() 